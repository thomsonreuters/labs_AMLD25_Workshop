{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c61b49-42b9-45cf-a872-52f0dd5eea23",
   "metadata": {},
   "source": [
    "# Exercise 2: Efficient Training with Resource Constraints and Capability Preservation ðŸš€\n",
    "## ðŸ“˜ Prerequisites\n",
    "From Exercise 1, we learned how to create high-quality training sets using smart sampling techniques. Now we'll build upon this knowledge while considering resource constraints and model capabilities preservation.\n",
    "\n",
    "## ðŸŽ¯ New Challenges\n",
    "### 1. Capability Preservation\n",
    "Even with high-quality data, models can \"forget\" previously learned capabilities during fine-tuning. We need to:\n",
    "\n",
    "* Maintain general knowledge\n",
    "* Preserve essential capabilities\n",
    "* Balance new and existing skills\n",
    "\n",
    "Generally, this is done by introducing different collections, and in this case, we will add a well-known collection for generic knowledge to our preference collection\n",
    "\n",
    "```\n",
    "trl-lib/ultrafeedback_binarized\n",
    "```\n",
    "\n",
    "### 2. Resource Optimization\n",
    "Training on full datasets, even high-quality ones, can be impractical due to:\n",
    "\n",
    "* Workshop time constraints\n",
    "* Cloud computing costs\n",
    "* In an enterprise environment, respect the development cycle duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72fff1-f380-4532-8218-af46c889d3cc",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a77fe-0f8a-4977-b183-cbc5d2653c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt\n",
    "! pip install flash-attn==2.7.3 --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4b693-0cd8-45d4-afaf-ee32b75ad9d5",
   "metadata": {},
   "source": [
    "### Testing GPU\n",
    "Please check if python recognize that you have GPU allocated, if not please go in `Settings`>`Accelerator`>`GPU T4 x 2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8e48b9-1001-42a5-8bfa-632b585584bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "#from tensorflow.python.client import device_lib\n",
    "repo_folder = os.getcwd().split('labs_AMLD25_Workshop')[0][:-1]+\"/labs_AMLD25_Workshop/src\" \n",
    "sys.path.append(repo_folder)\n",
    "\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42e06e-970a-495d-893c-3ec156ece907",
   "metadata": {},
   "source": [
    "if you get two GPUs you can manually assign them using env variables. This step is optional since they should be automatically recognized by pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0147144f-ee68-4958-b824-b1ec9ba9d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\" ## turning off WandB logging\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6b5f5d1-fed7-4e3d-9c26-9e702e98c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from typing import Optional, List, Dict\n",
    "import datasets\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk, \n",
    "    DatasetDict,\n",
    "    concatenate_datasets\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator, PartialState\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    DPOTrainer,\n",
    "    DPOConfig,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    ")\n",
    "\n",
    "from trlabs.rl.data import (\n",
    "    get_datasets, \n",
    "    DataArguments\n",
    ")\n",
    "\n",
    "from trlabs.utils import *\n",
    "\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5edfd-ffd7-4d44-b44b-d02c71d53a65",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfac9f8-8a42-45ec-a885-997178768a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    \"torch_dtype\": \"bfloat16\",\n",
    "    \"use_peft\": True, \n",
    "    \"lora_r\": 64,        \n",
    "    \"lora_alpha\": 32,    # Stronger updates\n",
    "    \"lora_dropout\": 0.1, # Prevent overfitting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12b23-7568-481d-b367-c19adc2a9100",
   "metadata": {},
   "source": [
    "### Data Config\n",
    "You can also leverage the preference dataset located in HF Hub `trl-lib/ultrafeedback_binarized`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236d9b51-e84a-4f97-b9f9-c97dd6a7a4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_params = {\n",
    "  \"dataset_name\": \"Mix 2\",\n",
    "  \"dataset_mixer\": {\n",
    "    \"trl-lib/ultrafeedback_binarized\": 0.02, ## 1220 samples over 61000\n",
    "    \"./data/AMLD25_reuters_gentitle_1k\": 1.,\n",
    "  },\n",
    "  \"dataset_splits\": [\"train\", \"test\"],\n",
    "  \"num_eval_samples\": 100,\n",
    "  \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c3af0-2d92-4814-9aad-2039f79347ca",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64d3765-75a0-4679-8d91-fe94a8c60b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_params =  {\n",
    "    ## General\n",
    "    \"output_dir\": f\"{model_config['model_name_or_path'].split('/')[0].lower()}_ex2_output\",\n",
    "     \"num_train_epochs\": 1,\n",
    "    \"beta\": 0.1,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 8,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    #@ context length and max length (max_new_token = max_length - max_prompt_length)\n",
    "    \"max_length\": 768,\n",
    "    \"max_prompt_length\":512,\n",
    "    ## Optimizer\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"learning_rate\": 2.0e-4,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"adam_epsilon\": 1.0e-8,\n",
    "    \"adam_beta1\": 0.9,\n",
    "    \"adam_beta2\": 0.999,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    ## Scheduler ##\n",
    "    \"warmup_steps\": 10,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    ## Logging\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_first_step\": True,\n",
    "    \"logging_steps\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03223d88-b7cf-4326-a7c1-d908886b47fa",
   "metadata": {},
   "source": [
    "## DPO Training Loop\n",
    "\n",
    "If you launch the training as it is set up you will see that it will take about 1 hour!!! \n",
    "\n",
    "You can get the same results in much less time. \n",
    "\n",
    "### Let's Play with our two collection!\n",
    "Now we have two collections, choosing **X** and **Y** fractions to balance the resulting contribution. But before you do that create collections with more smart sampling\n",
    "\n",
    "```python\n",
    "data_params = {\n",
    "  \"dataset_name\": \"Mix 2\",\n",
    "  \"dataset_mixer\": {\n",
    "    \"trl-lib/ultrafeedback_binarized\": Y,\n",
    "    \"./data/AMLD25_reuters_gentitle_1k\": X,\n",
    "  },\n",
    "  \"dataset_splits\": [\"train\", \"test\"],\n",
    "  \"num_eval_samples\": 100,\n",
    "  \"seed\": 42\n",
    "}\n",
    "```\n",
    "\n",
    "In order to achive the best performance. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Note:\n",
    "A fraction of 0.1 for collection`\"trl-lib/ultrafeedback_binarized\"` means that we select 10% of the training size from this collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90e8808d-30d6-48d9-ade9-c8acbe7fad29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from trlabs.rl.train import dpo\n",
    "\n",
    "dpo(data_params, training_params, model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82920c4-f68f-4fcd-a776-fdbd52cfec01",
   "metadata": {},
   "source": [
    "## Give a look to the Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "446ae29f-ebc8-4a4d-9f04-3046f6fbae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trlabs.utils import dataset_creation, not_relevant_data\n",
    "\n",
    "SYSTEM_PROMPT = 'You are an advanced AI system specialised in providing Reuters News title given a body text of the news.'\n",
    "INSTRUCTION = \"The title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\"\n",
    "\n",
    "dataset = load_dataset(\"ucirvine/reuters21578\", 'ModApte', trust_remote_code=True)\n",
    "dataset = dataset.filter(not_relevant_data).shuffle(seed=42).map(dataset_creation, fn_kwargs={\"system_prompt\": SYSTEM_PROMPT, \"instruction\": INSTRUCTION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe6f14bb-d51b-4c33-9ff4-77d1f159f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trlabs.rl.eval import setup_model_and_lora, generate\n",
    "\n",
    "index =33\n",
    "prompt = dataset[\"test\"][index][\"system\"]+dataset[\"test\"][index][\"messages\"]\n",
    "\n",
    "model, tokenizer = setup_model_and_lora(\n",
    "    base_model_name = model_config[\"model_name_or_path\"], \n",
    "    lora_path = training_params[\"output_dir\"]\n",
    ")\n",
    "\n",
    "response = generate(prompt, model, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2a606-4f97-40da-9c54-6baa8c72922d",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "if you do not provide a lora_path you can check the base model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d2537-aa3a-414c-a6c4-f75f8d47645f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
