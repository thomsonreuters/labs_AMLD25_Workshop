{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83e9e4b-c11c-4bf1-bce9-4d7d0903d785",
   "metadata": {},
   "source": [
    "# Exercise 4 (optional): Setup an Online DPO/RPO training ðŸš€ðŸš€ðŸš€\n",
    "## ðŸ“˜ Prerequisites\n",
    "* Exercise 1: Smart dataset sampling for quality\n",
    "* Exercise 2: Resource-efficient training strategies\n",
    "* Exercise 3: Optimizing RPO Training with Î± Parameter Tuning \n",
    "\n",
    "## ðŸŽ¯ The Challenge\n",
    "**Online DPO Training Loop**: Using the `OnlineDPOTrainer` and `OnlineDPOConfig` classes from trl lib; please add in trlabs.rl.train a new training function to run an onlinedpo training\n",
    "\n",
    "```python\n",
    "from trlabs.rl.train import onlinedpo\n",
    "\n",
    "onlinedpo(data_params, training_params, model_config)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72fff1-f380-4532-8218-af46c889d3cc",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070a77fe-0f8a-4977-b183-cbc5d2653c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt\n",
    "! pip install flash-attn==2.7.3 --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4b693-0cd8-45d4-afaf-ee32b75ad9d5",
   "metadata": {},
   "source": [
    "### Testing GPU\n",
    "Please check if python recognize that you have GPU allocated, if not please go in `Settings`>`Accelerator`>`GPU T4 x 2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8e48b9-1001-42a5-8bfa-632b585584bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "#from tensorflow.python.client import device_lib\n",
    "repo_folder = os.getcwd().split('labs_AMLD25_Workshop')[0][:-1]+\"/labs_AMLD25_Workshop/src\" \n",
    "sys.path.append(repo_folder)\n",
    "\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42e06e-970a-495d-893c-3ec156ece907",
   "metadata": {},
   "source": [
    "if you get two GPUs you can manually assign them using env variables. This step is optional since they should be automatically recognized by pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147144f-ee68-4958-b824-b1ec9ba9d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\" ## turning off WandB logging\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5f5d1-fed7-4e3d-9c26-9e702e98c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from typing import Optional, List, Dict\n",
    "import datasets\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk, \n",
    "    DatasetDict,\n",
    "    concatenate_datasets\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator, PartialState\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    DPOTrainer,\n",
    "    DPOConfig,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    ")\n",
    "\n",
    "from trlabs.rl.data import get_datasets\n",
    "from trlabs.rl.train import dpo\n",
    "\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5edfd-ffd7-4d44-b44b-d02c71d53a65",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfac9f8-8a42-45ec-a885-997178768a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    \"torch_dtype\": \"bfloat16\",\n",
    "    ##\"attn_implementation\": \"flash_attention_2\",\n",
    "    \"use_peft\": True, \n",
    "    \"lora_r\": 32,\n",
    "    \"lora_alpha\": 16,  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12b23-7568-481d-b367-c19adc2a9100",
   "metadata": {},
   "source": [
    "### Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236d9b51-e84a-4f97-b9f9-c97dd6a7a4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_params = {\n",
    "  \"dataset_name\": \"Mix 2\",\n",
    "  \"dataset_mixer\": {\n",
    "    \"trl-lib/ultrafeedback_binarized\": 0.01,\n",
    "    \"./data/AMLD25_reuters_gentitle_1k\": 0.5,\n",
    "  },\n",
    "  \"dataset_splits\": [\"train\", \"test\"],\n",
    "  \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c3af0-2d92-4814-9aad-2039f79347ca",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64d3765-75a0-4679-8d91-fe94a8c60b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_params =  {\n",
    "    ## RPO loss active \n",
    "    ## alpha is the multiplier of NLL loss\n",
    "    \"rpo_alpha\": 1.,\n",
    "    ## General\n",
    "    \"output_dir\": f\"{model_config['model_name_or_path'].split('/')[0].lower()}_ex4_output\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"learning_rate\": 5.0e-7,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 10,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_length\": 1024,\n",
    "    \"max_prompt_length\":512,\n",
    "    ## Optimizer\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"learning_rate\": 2.0e-7,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"adam_epsilon\": 1.0e-8,\n",
    "    \"adam_beta1\": 0.9,\n",
    "    \"adam_beta2\": 0.999,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    ## Scheduler ##\n",
    "    \"warmup_steps\": 10,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    ## Logging\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_first_step\": True,\n",
    "    \"logging_steps\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03223d88-b7cf-4326-a7c1-d908886b47fa",
   "metadata": {},
   "source": [
    "Please, pay attention that OnlineDPOTrainer requires a Judge model or a Reward Model to assess the generation. This requires another model to be allocated in the GPU memory making the limited HW a strong constraint. \n",
    "\n",
    "For this excercise, please use either a ligth Judge or an model API (see [here](https://huggingface.co/docs/trl/main/en/judges), and pick the best).\n",
    "\n",
    "The scope of this excersise is to familiarize with the online DPO and its integration (see [here](https://huggingface.co/docs/trl/online_dpo_trainer)); \n",
    "\n",
    "\n",
    "#### Note:\n",
    "2 T4 GPUs may not be enough to run the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f68dd-87ec-4c48-b5a2-9b6905a00bec",
   "metadata": {},
   "source": [
    "```python\n",
    "class OnlineDPOTrainer(Trainer):\n",
    "    r\"\"\"\n",
    "    Initialize OnlineDPOTrainer.\n",
    "\n",
    "    Args:\n",
    "        model (`transformers.PreTrainedModel` or `torch.nn.Module`):\n",
    "            The model to train, preferably an `AutoModelForCausalLM`.\n",
    "        ref_model (`transformers.PreTrainedModel` or `torch.nn.Module` or `None`):\n",
    "            The reference model to use for training. If None is specified, the reference model will be created from\n",
    "            the model.\n",
    "        reward_model (`transformers.PreTrainedModel` or `torch.nn.Module` or `None`):\n",
    "            The reward model to score completions with, preferably an `AutoModelForSequenceClassification`.\n",
    "        judge (`BasePairwiseJudge`):\n",
    "            The judge to use for pairwise comparison of model completions.\n",
    "        args (`OnlineDPOConfig`):\n",
    "            The online DPO config arguments to use for training.\n",
    "        data_collator (`transformers.DataCollator`):\n",
    "            The data collator to use for training. If None is specified, the default data collator (`DPODataCollatorWithPadding`) will be used\n",
    "            which will pad the sequences to the maximum length of the sequences in the batch, given a dataset of paired sequences.\n",
    "        train_dataset (`datasets.Dataset`):\n",
    "            The dataset to use for training.\n",
    "        eval_dataset (`datasets.Dataset`):\n",
    "            The dataset to use for evaluation.\n",
    "        processing_class (`PreTrainedTokenizerBase` or `BaseImageProcessor` or `FeatureExtractionMixin` or `ProcessorMixin`, *optional*):\n",
    "            Processing class used to process the data. If provided, will be used to automatically process the inputs\n",
    "            for the model, and it will be saved along the model to make it easier to rerun an interrupted training or\n",
    "            reuse the fine-tuned model.\n",
    "        peft_config (`dict`):\n",
    "            The peft config to use for training.\n",
    "        compute_metrics (`Callable[[EvalPrediction], dict]`, *optional*):\n",
    "            The function to use to compute the metrics. Must take a `EvalPrediction` and return\n",
    "            a dictionary string to metric values.\n",
    "        callbacks (`list[transformers.TrainerCallback]`):\n",
    "            The callbacks to use for training.\n",
    "        optimizers (`tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR]`):\n",
    "            The optimizer and scheduler to use for training.\n",
    "        preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`):\n",
    "            The function to use to preprocess the logits before computing the metrics.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4124ded-f2b7-47ba-92da-fe6b99d6ecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
