{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4411c7d0-adb8-4e71-b606-4f3207743cf3","cell_type":"markdown","source":"#  Exercise 3: Optimizing RPO Training with Œ± Parameter Tuning üéõÔ∏è\n## üìò Prerequisites\n* Exercise 1: Smart dataset sampling for quality\n* Exercise 2: Resource-efficient training strategies\n## üéØ The Challenge\nThe RPO (Regularized Preference Optimization) Œ± parameter critically affects:\n\n* Training stability\n* Preference versus instructFT learning strength\n* Base model knowledge preservation and task alignment","metadata":{}},{"id":"fa12d2f5-6aec-41dd-ac5c-2a887d565325","cell_type":"markdown","source":"### Git Clone","metadata":{}},{"id":"c2a8c68b-b2a7-4dfb-ae44-19f06759f0c0","cell_type":"code","source":"! git clone https://github.com/thomsonreuters/labs_AMLD25_Workshop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:22:18.402948Z","iopub.execute_input":"2025-02-12T14:22:18.403169Z","iopub.status.idle":"2025-02-12T14:22:19.825178Z","shell.execute_reply.started":"2025-02-12T14:22:18.403148Z","shell.execute_reply":"2025-02-12T14:22:19.824175Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'labs_AMLD25_Workshop'...\nremote: Enumerating objects: 360, done.\u001b[K\nremote: Counting objects: 100% (42/42), done.\u001b[K\nremote: Compressing objects: 100% (34/34), done.\u001b[K\nremote: Total 360 (delta 15), reused 22 (delta 7), pack-reused 318 (from 1)\u001b[K\nReceiving objects: 100% (360/360), 4.56 MiB | 16.21 MiB/s, done.\nResolving deltas: 100% (207/207), done.\n","output_type":"stream"}],"execution_count":1},{"id":"561f67f1-644c-49eb-a903-ce28a0ba179f","cell_type":"markdown","source":"### Install dependencies","metadata":{}},{"id":"fd1d7c8e-a7ac-4fcd-81cd-5c867ddabecc","cell_type":"code","source":"! pip install -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt\n! pip install flash-attn==2.7.3 --no-build-isolation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:22:35.707252Z","iopub.execute_input":"2025-02-12T14:22:35.707550Z","iopub.status.idle":"2025-02-12T14:23:13.528730Z","shell.execute_reply.started":"2025-02-12T14:22:35.707526Z","shell.execute_reply":"2025-02-12T14:23:13.527883Z"}},"outputs":[{"name":"stdout","text":"Collecting accelerate==1.3.0 (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1))\n  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\nCollecting bitsandbytes==0.45.1 (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 2))\n  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: datasets==3.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.2.0)\nRequirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 4)) (0.14.0)\nCollecting transformers==4.48.1 (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 5))\n  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting trl==0.13.0 (from -r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 6))\n  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2.5.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (0.28.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (19.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.11.11)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.1->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 5)) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.48.1->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 5)) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl==0.13.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 6)) (13.9.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (2025.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.13.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 6)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.13.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 6)) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.13.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 6)) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 3)) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate==1.3.0->-r /kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/requirements.txt (line 1)) (2024.2.0)\nDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, accelerate, trl, bitsandbytes\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.2.1\n    Uninstalling accelerate-1.2.1:\n      Successfully uninstalled accelerate-1.2.1\nSuccessfully installed accelerate-1.3.0 bitsandbytes-0.45.1 transformers-4.48.1 trl-0.13.0\nCollecting flash-attn==2.7.3\n  Downloading flash_attn-2.7.3.tar.gz (3.2 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.7.3) (2.5.1+cu121)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.7.3) (0.8.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.7.3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.3) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn==2.7.3) (3.0.2)\nBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for flash-attn: filename=flash_attn-2.7.3-cp310-cp310-linux_x86_64.whl size=191342964 sha256=cd0ead6ad92bff21f90cf0aecdf859bc7145bf4e7dc8ed1fdc3cc38299651ce4\n  Stored in directory: /root/.cache/pip/wheels/85/d7/10/a74c9fe5ffe6ff306b27a220b2bf2f37d907b68fdcd138cdda\nSuccessfully built flash-attn\nInstalling collected packages: flash-attn\nSuccessfully installed flash-attn-2.7.3\n","output_type":"stream"}],"execution_count":2},{"id":"1cb3652f-4e64-4c16-98cb-7a4fac379f39","cell_type":"markdown","source":"### Testing GPU\nPlease check if python recognize that you have GPU allocated, if not please go in `Settings`>`Accelerator`>`GPU T4 x 2` ","metadata":{}},{"id":"640bcb60-48c6-4191-ad56-bd74b1e2032d","cell_type":"code","source":"import os, sys\n\n# from tensorflow.python.client import device_lib\nrepo_folder = os.getcwd().split('labs_AMLD25_Workshop')[0]+\"/labs_AMLD25_Workshop/src\" \nsys.path.append(repo_folder)\n\n# UNCOMMENT TO CHECK GPU HW\n# device_lib.list_local_devices()","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:13.530132Z","iopub.execute_input":"2025-02-12T14:23:13.530466Z","iopub.status.idle":"2025-02-12T14:23:13.534632Z","shell.execute_reply.started":"2025-02-12T14:23:13.530441Z","shell.execute_reply":"2025-02-12T14:23:13.533753Z"}},"outputs":[],"execution_count":3},{"id":"7e4c23ec-b957-4812-bd55-3fa387da1b99","cell_type":"markdown","source":"if you get two GPUs you can manually assign them using env variables. This step is optional since they should be automatically recognized by pytorch ","metadata":{}},{"id":"1943df5a-f309-4233-bc50-e49dc8456907","cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\" ## turning off WandB logging\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n\nrl_foolder = \"labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:13.536383Z","iopub.execute_input":"2025-02-12T14:23:13.536595Z","iopub.status.idle":"2025-02-12T14:23:13.558162Z","shell.execute_reply.started":"2025-02-12T14:23:13.536578Z","shell.execute_reply":"2025-02-12T14:23:13.557325Z"}},"outputs":[],"execution_count":4},{"id":"c6b5f5d1-fed7-4e3d-9c26-9e702e98c518","cell_type":"code","source":"import torch\n\nfrom typing import Optional, List, Dict\nimport datasets\nfrom datasets import (\n    load_dataset, \n    load_from_disk, \n    DatasetDict,\n    concatenate_datasets\n)\n\nfrom accelerate import Accelerator, PartialState\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom trl import (\n    ModelConfig,\n    DPOTrainer,\n    DPOConfig,\n    TrlParser,\n    get_kbit_device_map,\n    get_peft_config,\n    get_quantization_config,\n)\n\nfrom trlabs.rl.data import (\n    get_datasets, \n    DataArguments\n)\n\nfrom trlabs.utils import *\n\nfrom trl.trainer.utils import SIMPLE_CHAT_TEMPLATE\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:13.559236Z","iopub.execute_input":"2025-02-12T14:23:13.559534Z","iopub.status.idle":"2025-02-12T14:23:37.927900Z","shell.execute_reply.started":"2025-02-12T14:23:13.559512Z","shell.execute_reply":"2025-02-12T14:23:37.927302Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":5},{"id":"67c5edfd-ffd7-4d44-b44b-d02c71d53a65","cell_type":"markdown","source":"### Model Config","metadata":{}},{"id":"5cfac9f8-8a42-45ec-a885-997178768a99","cell_type":"code","source":"model_config = {\n    \"model_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n    \"torch_dtype\": \"bfloat16\",\n    \"use_peft\": True, \n    \"lora_r\": 64,        \n    \"lora_alpha\": 32,    # Stronger updates\n    \"lora_dropout\": 0.1, # Prevent overfitting\n}","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:37.928686Z","iopub.execute_input":"2025-02-12T14:23:37.928986Z","iopub.status.idle":"2025-02-12T14:23:37.932772Z","shell.execute_reply.started":"2025-02-12T14:23:37.928957Z","shell.execute_reply":"2025-02-12T14:23:37.931979Z"}},"outputs":[],"execution_count":6},{"id":"c9b12b23-7568-481d-b367-c19adc2a9100","cell_type":"markdown","source":"### Data Config","metadata":{}},{"id":"236d9b51-e84a-4f97-b9f9-c97dd6a7a4f0","cell_type":"code","source":"data_params = {\n  \"dataset_name\": \"Mix 1\",\n  \"dataset_mixer\": {\n    # For time constraints, use only our preference collection \n    # to see the effect of the RPO objective and its HP\n    # \"trl-lib/ultrafeedback_binarized\": 0.02, \n    f\"{rl_foolder}/data/AMLD25_reuters_gentitle_1k\": 1.,\n  },\n  \"dataset_splits\": [\"train\", \"test\"],\n  \"num_eval_samples\": 100,\n  \"seed\": 42\n}","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:37.933572Z","iopub.execute_input":"2025-02-12T14:23:37.933812Z","iopub.status.idle":"2025-02-12T14:23:37.984889Z","shell.execute_reply.started":"2025-02-12T14:23:37.933773Z","shell.execute_reply":"2025-02-12T14:23:37.983986Z"}},"outputs":[],"execution_count":7},{"id":"e67c3af0-2d92-4814-9aad-2039f79347ca","cell_type":"markdown","source":"### Training Config","metadata":{}},{"id":"a64d3765-75a0-4679-8d91-fe94a8c60b80","cell_type":"code","source":"training_params =  {\n    ## RPO loss active \n    ## alpha is the multiplier of NLL loss\n    \"rpo_alpha\": .5,\n    ## General\n    \"output_dir\": f\"{model_config['model_name_or_path'].split('/')[0].lower()}_ex3_output\",\n    \"num_train_epochs\": 1,\n    \"beta\": 0.1,\n    \"eval_strategy\": \"steps\",\n    \"eval_steps\": 8,\n    \"per_device_train_batch_size\": 1,\n    \"per_device_eval_batch_size\": 1,\n    \"gradient_accumulation_steps\": 8,\n    #@ context length and max length (max_new_token = max_length - max_prompt_length)\n    \"max_length\": 768,\n    \"max_prompt_length\":512,\n    ## Optimizer\n    \"optim\": \"adamw_torch\",\n    \"learning_rate\": 2.0e-4,\n    \"weight_decay\": 0.001,\n    \"adam_epsilon\": 1.0e-8,\n    \"adam_beta1\": 0.9,\n    \"adam_beta2\": 0.999,\n    \"max_grad_norm\": 1.0,\n    ## Scheduler ##\n    \"warmup_steps\": 10,\n    \"lr_scheduler_type\": \"cosine\",\n    ## Logging\n    \"log_level\": \"info\",\n    \"logging_first_step\": True,\n    \"logging_steps\": 10\n}","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:37.985742Z","iopub.execute_input":"2025-02-12T14:23:37.985989Z","iopub.status.idle":"2025-02-12T14:23:37.998971Z","shell.execute_reply.started":"2025-02-12T14:23:37.985970Z","shell.execute_reply":"2025-02-12T14:23:37.998295Z"}},"outputs":[],"execution_count":8},{"id":"03223d88-b7cf-4326-a7c1-d908886b47fa","cell_type":"markdown","source":"### RPO Training Loop","metadata":{}},{"id":"0d7c6796-a16a-4fb5-bae8-e68f2c6028f1","cell_type":"code","source":"from trlabs.rl.train import dpo\n\ndpo(data_params, training_params, model_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:23:38.000818Z","iopub.execute_input":"2025-02-12T14:23:38.001069Z","iopub.status.idle":"2025-02-12T14:43:34.997749Z","shell.execute_reply.started":"2025-02-12T14:23:38.001026Z","shell.execute_reply":"2025-02-12T14:43:34.997030Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ca49a6f6ac4af0915c2b683b4ba7c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9a3959a6ff4499294625de63912161b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc76ac0fa6f04785a43b58af575a833d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7c1eb796ac4fc8a9547bdeb717349b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6dad35a4694353b195fc5ee19615d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"847ab79fa49b4ce482c4698f69b281fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979abcaa39fc41ceaf488e98c3cd049c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting prompt from train dataset:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f64f2b91ef45a0b7d579b28a743faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba87690c76246beb5c85a3668f41e06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting prompt from eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80fb8155baa423f854e336999568795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7bceba74b94e20b488c61cd5d6b025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c02624529f4bcca608daf0c7240118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5329b3e3e8a94adaa30023f96aab28c6"}},"metadata":{}},{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 987\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Training with DataParallel so batch size has been adjusted to: 2\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 8\n  Total optimization steps = 61\n  Number of trainable parameters = 4,325,376\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [61/61 18:21, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n      <th>Nll Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>8</td>\n      <td>17.812500</td>\n      <td>1.799219</td>\n      <td>50.574600</td>\n      <td>1.977000</td>\n      <td>0.989000</td>\n      <td>1.406250</td>\n      <td>1.343750</td>\n      <td>0.570000</td>\n      <td>0.066406</td>\n      <td>-42.250000</td>\n      <td>-40.750000</td>\n      <td>-3.078125</td>\n      <td>-3.078125</td>\n      <td>2.250000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>16.414900</td>\n      <td>1.521406</td>\n      <td>52.146300</td>\n      <td>1.918000</td>\n      <td>0.959000</td>\n      <td>2.453125</td>\n      <td>2.359375</td>\n      <td>0.560000</td>\n      <td>0.099121</td>\n      <td>-31.750000</td>\n      <td>-30.625000</td>\n      <td>-3.125000</td>\n      <td>-3.125000</td>\n      <td>1.687500</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>12.388300</td>\n      <td>1.450234</td>\n      <td>52.725500</td>\n      <td>1.897000</td>\n      <td>0.948000</td>\n      <td>2.609375</td>\n      <td>2.406250</td>\n      <td>0.620000</td>\n      <td>0.192383</td>\n      <td>-30.250000</td>\n      <td>-30.125000</td>\n      <td>-3.093750</td>\n      <td>-3.093750</td>\n      <td>1.609375</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>11.655500</td>\n      <td>1.397500</td>\n      <td>52.828900</td>\n      <td>1.893000</td>\n      <td>0.946000</td>\n      <td>2.718750</td>\n      <td>2.453125</td>\n      <td>0.640000</td>\n      <td>0.265625</td>\n      <td>-29.125000</td>\n      <td>-29.625000</td>\n      <td>-3.046875</td>\n      <td>-3.046875</td>\n      <td>1.546875</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>11.412500</td>\n      <td>1.374141</td>\n      <td>52.898400</td>\n      <td>1.890000</td>\n      <td>0.945000</td>\n      <td>2.750000</td>\n      <td>2.437500</td>\n      <td>0.660000</td>\n      <td>0.314453</td>\n      <td>-28.750000</td>\n      <td>-29.750000</td>\n      <td>-3.000000</td>\n      <td>-3.000000</td>\n      <td>1.531250</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>11.412500</td>\n      <td>1.358047</td>\n      <td>53.030400</td>\n      <td>1.886000</td>\n      <td>0.943000</td>\n      <td>2.781250</td>\n      <td>2.453125</td>\n      <td>0.660000</td>\n      <td>0.337891</td>\n      <td>-28.375000</td>\n      <td>-29.625000</td>\n      <td>-2.968750</td>\n      <td>-2.984375</td>\n      <td>1.507812</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>11.223400</td>\n      <td>1.355469</td>\n      <td>52.836000</td>\n      <td>1.893000</td>\n      <td>0.946000</td>\n      <td>2.796875</td>\n      <td>2.453125</td>\n      <td>0.660000</td>\n      <td>0.343750</td>\n      <td>-28.375000</td>\n      <td>-29.750000</td>\n      <td>-2.968750</td>\n      <td>-2.968750</td>\n      <td>1.507812</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nSaving model checkpoint to qwen_ex3_output/checkpoint-61\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\ntokenizer config file saved in qwen_ex3_output/checkpoint-61/tokenizer_config.json\nSpecial tokens file saved in qwen_ex3_output/checkpoint-61/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:51]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to qwen_ex3_output\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =     0.9879\n  eval_logits/chosen      =    -2.9688\n  eval_logits/rejected    =    -2.9688\n  eval_logps/chosen       =     -28.25\n  eval_logps/rejected     =    -29.625\n  eval_loss               =     1.3527\n  eval_nll_loss           =     1.5078\n  eval_rewards/accuracies =       0.66\n  eval_rewards/chosen     =     2.7969\n  eval_rewards/margins    =     0.3477\n  eval_rewards/rejected   =     2.4531\n  eval_runtime            = 0:00:52.87\n  eval_samples_per_second =      1.891\n  eval_steps_per_second   =      0.946\n","output_type":"stream"},{"name":"stderr","text":"tokenizer config file saved in qwen_ex3_output/tokenizer_config.json\nSpecial tokens file saved in qwen_ex3_output/special_tokens_map.json\n","output_type":"stream"}],"execution_count":9},{"id":"6139d870-7358-46d3-8b93-15b0a925051d","cell_type":"markdown","source":"## Your turn!\nPlay with rho_alpha to get the best contribution from the two loss terms","metadata":{}},{"id":"6c4a6a30-94e9-4ab3-98c5-0baad2e1618d","cell_type":"markdown","source":"## Give a look to the Model Generation","metadata":{}},{"id":"fa65c1cb-b96d-433a-b250-b42a4f98e700","cell_type":"code","source":"from trlabs.utils import dataset_creation, not_relevant_data\n\nSYSTEM_PROMPT = 'You are an advanced AI system specialised in providing Reuters News title given a body text of the news.'\nINSTRUCTION = \"The title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\"\n\ndataset = load_dataset(\"ucirvine/reuters21578\", 'ModApte', trust_remote_code=True)\ndataset = dataset.filter(not_relevant_data).shuffle(seed=42).map(dataset_creation, fn_kwargs={\"system_prompt\": SYSTEM_PROMPT, \"instruction\": INSTRUCTION})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:43:34.999456Z","iopub.execute_input":"2025-02-12T14:43:34.999696Z","iopub.status.idle":"2025-02-12T14:43:44.585952Z","shell.execute_reply.started":"2025-02-12T14:43:34.999676Z","shell.execute_reply":"2025-02-12T14:43:44.584932Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f583252dade44cc7b82458e0a58b2240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reuters21578.py:   0%|          | 0.00/17.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c3648b904074b21a92bb8009cdab41a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"reuters21578.tar.gz:   0%|          | 0.00/8.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f964af3f016645d1b57be213559f2101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3299 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"922d312954c7453a8849a89589eb4517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9603 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba032d075fd54715b1c5aebaf8e861d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unused split:   0%|          | 0/722 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c77d985e3c5d4d7da09f8762fe787cef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3299 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a35a7a3d55214ab88abd84192d1ecbca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/9603 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"582a3e2137074453baf6a53d25b12249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/722 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"060ab125011044bbac8c1d8ff9b80d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3295 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c0254996cc4642be32da24104db486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9583 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96640174c65e446f86ecbeac0d800a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/722 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b98d0dd520b349f5bf7d7b27400b883b"}},"metadata":{}}],"execution_count":10},{"id":"07b7a230-c230-4bbe-ab54-b9965a9b5219","cell_type":"code","source":"from trlabs.rl.eval import setup_model_and_lora, generate\n\nindex =10\nprompt = dataset[\"test\"][index][\"system\"]+dataset[\"test\"][index][\"messages\"]\n\nmodel, tokenizer = setup_model_and_lora(\n    base_model_name = model_config[\"model_name_or_path\"], \n    lora_path = training_params[\"output_dir\"]\n)\n\nresponse = generate(prompt, model, tokenizer)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:43:44.586836Z","iopub.execute_input":"2025-02-12T14:43:44.587081Z","iopub.status.idle":"2025-02-12T14:43:48.621093Z","shell.execute_reply.started":"2025-02-12T14:43:44.587033Z","shell.execute_reply":"2025-02-12T14:43:48.620193Z"}},"outputs":[{"name":"stderr","text":"loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer_config.json\nloading file chat_template.jinja from cache at None\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2-0.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\nloading file vocab.json\nloading file merges.txt\nloading file tokenizer.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nloading file tokenizer_config.json\nloading file chat_template.jinja\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 151646. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"system\nYou are an advanced AI system specialised in providing Reuters News title given a body text of the news.\nuser\nFleet Financial Group said its shareholders approved an increase in shares of the company's authorized common stock to 100,000,000 shares from 75,000,000 shares currently. The company said shareholders approved the move at the annual meeting in Providence today when the company reported that its first quarter earnings rose to 38.5 mln dlrs, or 73 cts a share, from 31.7 mln dlrs, or 60 cts a share, in the first quarter 1986. J. Terence Murray, chairman and president of Fleet Financial, said, \"Fleet's mortgage banking activities in particular continued to produce signficant income increases (in the first quarter).\" Murray said Fleet's mortgage servicing portfolio reached 22.1 billion dlrs by March 31, including 1.8 billion dlrs purchased in March.\n\nThe title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\nassistant\nFLEET FINANCIAL GROUP APPROVES SHARE HRA\n","output_type":"stream"}],"execution_count":11},{"id":"1430b3a2-8f08-4b93-a5ee-0fa1f257db82","cell_type":"markdown","source":"#### Note: \nif you do not provide lora_path you can check the base model output","metadata":{}},{"id":"f4380c12-4c66-46e8-9a12-6a4082c441ff","cell_type":"markdown","source":"## Solution","metadata":{}},{"id":"46b0f457-f67e-4c66-968f-00ad7ef0f6af","cell_type":"code","source":"from trlabs.utils import *\n\ndataset = load_from_disk(\"/kaggle/working/labs_AMLD25_Workshop/sessions/4_RLalignment_and_DPO/data/AMLD25_reuters_gentitle_1k\").filter(reuters_cleaning_dataset)\ndataset.save_to_disk(\"AMLD25_reuters_gentitle_0.5k_cleaned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:43:48.622027Z","iopub.execute_input":"2025-02-12T14:43:48.622371Z","iopub.status.idle":"2025-02-12T14:43:48.779815Z","shell.execute_reply.started":"2025-02-12T14:43:48.622338Z","shell.execute_reply":"2025-02-12T14:43:48.778998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865049bd37414799ac3d184763d45345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/496 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee01832dcba4bd28bba5ceab56dbfa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e678477b28de4fea924d23a076e428d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/196 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7456d1b4b4f9460bad28a01e887c40f8"}},"metadata":{}}],"execution_count":12},{"id":"c80b2b82-c0d4-4b63-b4f2-02836289eb4b","cell_type":"code","source":"data_params = {\n  \"dataset_name\": \"Mix 1\",\n  \"dataset_mixer\": {\n    f\"AMLD25_reuters_gentitle_0.5k_cleaned\": 1.,\n  },\n  \"dataset_splits\": [\"train\", \"test\"],\n  \"num_eval_samples\": 100,\n  \"seed\": 42\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:43:48.781462Z","iopub.execute_input":"2025-02-12T14:43:48.781693Z","iopub.status.idle":"2025-02-12T14:43:48.785374Z","shell.execute_reply.started":"2025-02-12T14:43:48.781671Z","shell.execute_reply":"2025-02-12T14:43:48.784735Z"}},"outputs":[],"execution_count":13},{"id":"254e4427-46ab-487d-84d5-0932c05b9021","cell_type":"code","source":"from trlabs.rl.train import dpo\n\ndpo(data_params, training_params, model_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:43:48.786139Z","iopub.execute_input":"2025-02-12T14:43:48.786383Z","iopub.status.idle":"2025-02-12T14:52:04.424332Z","shell.execute_reply.started":"2025-02-12T14:43:48.786351Z","shell.execute_reply":"2025-02-12T14:52:04.423344Z"}},"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2-0.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\nloading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer_config.json\nloading file chat_template.jinja from cache at None\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Extracting prompt from train dataset:   0%|          | 0/446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1340c232898b42bbb8371f5c9527cde1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54c8241a17a439cb28259c85518cdef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting prompt from eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5445696ea14dc483862262873fc45b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc5f8498b0e40d69fc1289b6c30fa32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebe21034a5a4d4fa70c9497a0a6cd82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a2fc0752a748d6aac514f85b87e03e"}},"metadata":{}},{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 446\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Training with DataParallel so batch size has been adjusted to: 2\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 8\n  Total optimization steps = 27\n  Number of trainable parameters = 4,325,376\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27/27 07:11, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/chosen</th>\n      <th>Logps/rejected</th>\n      <th>Logits/chosen</th>\n      <th>Logits/rejected</th>\n      <th>Nll Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>8</td>\n      <td>19.703100</td>\n      <td>1.843125</td>\n      <td>46.770000</td>\n      <td>2.138000</td>\n      <td>1.069000</td>\n      <td>1.484375</td>\n      <td>1.375000</td>\n      <td>0.580000</td>\n      <td>0.104980</td>\n      <td>-43.000000</td>\n      <td>-45.500000</td>\n      <td>-3.093750</td>\n      <td>-3.062500</td>\n      <td>2.375000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>16.523400</td>\n      <td>1.503750</td>\n      <td>47.148500</td>\n      <td>2.121000</td>\n      <td>1.060000</td>\n      <td>2.546875</td>\n      <td>2.281250</td>\n      <td>0.620000</td>\n      <td>0.267578</td>\n      <td>-32.250000</td>\n      <td>-36.500000</td>\n      <td>-3.109375</td>\n      <td>-3.093750</td>\n      <td>1.789062</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>12.671900</td>\n      <td>1.431719</td>\n      <td>48.046100</td>\n      <td>2.081000</td>\n      <td>1.041000</td>\n      <td>2.734375</td>\n      <td>2.375000</td>\n      <td>0.620000</td>\n      <td>0.357422</td>\n      <td>-30.375000</td>\n      <td>-35.500000</td>\n      <td>-3.078125</td>\n      <td>-3.046875</td>\n      <td>1.679688</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\nSaving model checkpoint to qwen_ex3_output/checkpoint-27\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\ntokenizer config file saved in qwen_ex3_output/checkpoint-27/tokenizer_config.json\nSpecial tokens file saved in qwen_ex3_output/checkpoint-27/special_tokens_map.json\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward. If rejected, prompt, rejected_reward, origin_response_c_r, chosen, date, chosen_reward are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:47]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to qwen_ex3_output\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =     0.9686\n  eval_logits/chosen      =    -3.0781\n  eval_logits/rejected    =    -3.0469\n  eval_logps/chosen       =     -30.25\n  eval_logps/rejected     =      -35.5\n  eval_loss               =      1.429\n  eval_nll_loss           =     1.6719\n  eval_rewards/accuracies =       0.63\n  eval_rewards/chosen     =       2.75\n  eval_rewards/margins    =     0.3652\n  eval_rewards/rejected   =      2.375\n  eval_runtime            = 0:00:48.22\n  eval_samples_per_second =      2.073\n  eval_steps_per_second   =      1.037\n","output_type":"stream"},{"name":"stderr","text":"tokenizer config file saved in qwen_ex3_output/tokenizer_config.json\nSpecial tokens file saved in qwen_ex3_output/special_tokens_map.json\n","output_type":"stream"}],"execution_count":14},{"id":"f00d9533-9ebe-4f15-ba22-e626b1be3c0e","cell_type":"markdown","source":"## Give a look to the Model Generation","metadata":{}},{"id":"dc0da087-fe9f-4d89-b447-340c3e7cf7f8","cell_type":"code","source":"from trlabs.utils import dataset_creation, not_relevant_data\n\nSYSTEM_PROMPT = 'You are an advanced AI system specialised in providing Reuters News title given a body text of the news.'\nINSTRUCTION = \"The title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\"\n\ndataset = load_dataset(\"ucirvine/reuters21578\", 'ModApte', trust_remote_code=True)\ndataset = dataset.filter(not_relevant_data).shuffle(seed=42).map(dataset_creation, fn_kwargs={\"system_prompt\": SYSTEM_PROMPT, \"instruction\": INSTRUCTION})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:52:04.426377Z","iopub.execute_input":"2025-02-12T14:52:04.426699Z","iopub.status.idle":"2025-02-12T14:52:05.055694Z","shell.execute_reply.started":"2025-02-12T14:52:04.426656Z","shell.execute_reply":"2025-02-12T14:52:05.055090Z"}},"outputs":[],"execution_count":15},{"id":"1c9823f9-6e37-49c6-af81-664cbdd61fda","cell_type":"code","source":"from trlabs.rl.eval import setup_model_and_lora, generate\n\nindex =10\nprompt = dataset[\"test\"][index][\"system\"]+dataset[\"test\"][index][\"messages\"]\n\nmodel, tokenizer = setup_model_and_lora(\n    base_model_name = model_config[\"model_name_or_path\"], \n    lora_path = training_params[\"output_dir\"]\n)\n\nresponse = generate(prompt, model, tokenizer)\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T14:52:05.056478Z","iopub.execute_input":"2025-02-12T14:52:05.056781Z","iopub.status.idle":"2025-02-12T14:52:08.792322Z","shell.execute_reply.started":"2025-02-12T14:52:05.056749Z","shell.execute_reply":"2025-02-12T14:52:08.791431Z"}},"outputs":[{"name":"stderr","text":"loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/vocab.json\nloading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/merges.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/tokenizer_config.json\nloading file chat_template.jinja from cache at None\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.48.1\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2-0.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-0.5B-Instruct/snapshots/c540970f9e29518b1d8f06ab8b24cba66ad77b6d/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\nloading file vocab.json\nloading file merges.txt\nloading file tokenizer.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nloading file tokenizer_config.json\nloading file chat_template.jinja\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 151646. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","output_type":"stream"},{"name":"stdout","text":"system\nYou are an advanced AI system specialised in providing Reuters News title given a body text of the news.\nuser\nFleet Financial Group said its shareholders approved an increase in shares of the company's authorized common stock to 100,000,000 shares from 75,000,000 shares currently. The company said shareholders approved the move at the annual meeting in Providence today when the company reported that its first quarter earnings rose to 38.5 mln dlrs, or 73 cts a share, from 31.7 mln dlrs, or 60 cts a share, in the first quarter 1986. J. Terence Murray, chairman and president of Fleet Financial, said, \"Fleet's mortgage banking activities in particular continued to produce signficant income increases (in the first quarter).\" Murray said Fleet's mortgage servicing portfolio reached 22.1 billion dlrs by March 31, including 1.8 billion dlrs purchased in March.\n\nThe title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\nassistant\nFLEET FINANCIAL GROUP APPROVES SHARE HISTORICAL INCREASE\n","output_type":"stream"}],"execution_count":16},{"id":"8da21abf-7cd0-4f2f-9f04-518690a40d2c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}