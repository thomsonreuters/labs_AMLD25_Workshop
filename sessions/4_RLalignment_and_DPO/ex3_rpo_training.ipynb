{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4411c7d0-adb8-4e71-b606-4f3207743cf3",
   "metadata": {},
   "source": [
    "#  Exercise 3: Optimizing RPO Training with α Parameter Tuning 🎛️\n",
    "## 📘 Prerequisites\n",
    "* Exercise 1: Smart dataset sampling for quality\n",
    "* Exercise 2: Resource-efficient training strategies\n",
    "## 🎯 The Challenge\n",
    "The RPO (Regularized Preference Optimization) α parameter critically affects:\n",
    "\n",
    "* Training stability\n",
    "* Preference versus instructFT learning strength\n",
    "* Base model knowledge preservation and task alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72fff1-f380-4532-8218-af46c889d3cc",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a77fe-0f8a-4977-b183-cbc5d2653c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt\n",
    "! pip install flash-attn==2.7.3 --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4b693-0cd8-45d4-afaf-ee32b75ad9d5",
   "metadata": {},
   "source": [
    "### Testing GPU\n",
    "Please check if python recognize that you have GPU allocated, if not please go in `Settings`>`Accelerator`>`GPU T4 x 2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8e48b9-1001-42a5-8bfa-632b585584bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# from tensorflow.python.client import device_lib\n",
    "repo_folder = os.getcwd().split('labs_AMLD25_Workshop')[0][:-1]+\"/labs_AMLD25_Workshop/src\" \n",
    "sys.path.append(repo_folder)\n",
    "\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42e06e-970a-495d-893c-3ec156ece907",
   "metadata": {},
   "source": [
    "if you get two GPUs you can manually assign them using env variables. This step is optional since they should be automatically recognized by pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0147144f-ee68-4958-b824-b1ec9ba9d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\" ## turning off WandB logging\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b5f5d1-fed7-4e3d-9c26-9e702e98c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from typing import Optional, List, Dict\n",
    "import datasets\n",
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk, \n",
    "    DatasetDict,\n",
    "    concatenate_datasets\n",
    ")\n",
    "\n",
    "from accelerate import Accelerator, PartialState\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    DPOTrainer,\n",
    "    DPOConfig,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    ")\n",
    "\n",
    "from trlabs.rl.data import (\n",
    "    get_datasets, \n",
    "    DataArguments\n",
    ")\n",
    "\n",
    "from trlabs.utils import *\n",
    "\n",
    "from trl.trainer.utils import SIMPLE_CHAT_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5edfd-ffd7-4d44-b44b-d02c71d53a65",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cfac9f8-8a42-45ec-a885-997178768a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    \"torch_dtype\": \"bfloat16\",\n",
    "    \"use_peft\": True, \n",
    "    \"lora_r\": 64,        \n",
    "    \"lora_alpha\": 32,    # Stronger updates\n",
    "    \"lora_dropout\": 0.1, # Prevent overfitting\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12b23-7568-481d-b367-c19adc2a9100",
   "metadata": {},
   "source": [
    "### Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236d9b51-e84a-4f97-b9f9-c97dd6a7a4f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_params = {\n",
    "  \"dataset_name\": \"Mix 1\",\n",
    "  \"dataset_mixer\": {\n",
    "    # For time constraints, use only our preference collection \n",
    "    # to see the effect of the RPO objective and its HP\n",
    "    # \"trl-lib/ultrafeedback_binarized\": 0.02, \n",
    "    \"./data/AMLD25_reuters_gentitle_1k\": 1.,\n",
    "  },\n",
    "  \"dataset_splits\": [\"train\", \"test\"],\n",
    "  \"num_eval_samples\": 100,\n",
    "  \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c3af0-2d92-4814-9aad-2039f79347ca",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64d3765-75a0-4679-8d91-fe94a8c60b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_params =  {\n",
    "    ## RPO loss active \n",
    "    ## alpha is the multiplier of NLL loss\n",
    "    \"rpo_alpha\": .5,\n",
    "    ## General\n",
    "    \"output_dir\": f\"{model_config['model_name_or_path'].split('/')[0].lower()}_ex3_output\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"beta\": 0.1,\n",
    "    \"eval_strategy\": \"steps\",\n",
    "    \"eval_steps\": 8,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    #@ context length and max length (max_new_token = max_length - max_prompt_length)\n",
    "    \"max_length\": 768,\n",
    "    \"max_prompt_length\":512,\n",
    "    ## Optimizer\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"learning_rate\": 2.0e-4,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"adam_epsilon\": 1.0e-8,\n",
    "    \"adam_beta1\": 0.9,\n",
    "    \"adam_beta2\": 0.999,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    ## Scheduler ##\n",
    "    \"warmup_steps\": 10,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    ## Logging\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_first_step\": True,\n",
    "    \"logging_steps\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03223d88-b7cf-4326-a7c1-d908886b47fa",
   "metadata": {},
   "source": [
    "### RPO Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d7c6796-a16a-4fb5-bae8-e68f2c6028f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trlabs.rl.train import dpo\n",
    "\n",
    "dpo(data_params, training_params, model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139d870-7358-46d3-8b93-15b0a925051d",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "Play with rho_alpha to get the best contribution from the two loss terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a6a30-94e9-4ab3-98c5-0baad2e1618d",
   "metadata": {},
   "source": [
    "## Give a look to the Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa65c1cb-b96d-433a-b250-b42a4f98e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trlabs.utils import dataset_creation, not_relevant_data\n",
    "\n",
    "SYSTEM_PROMPT = 'You are an advanced AI system specialised in providing Reuters News title given a body text of the news.'\n",
    "INSTRUCTION = \"The title should be in capital letters and between 6 and 8 words in length. Please provide only the title as output and no other text or explanation.\"\n",
    "\n",
    "dataset = load_dataset(\"ucirvine/reuters21578\", 'ModApte', trust_remote_code=True)\n",
    "dataset = dataset.filter(not_relevant_data).shuffle(seed=42).map(dataset_creation, fn_kwargs={\"system_prompt\": SYSTEM_PROMPT, \"instruction\": INSTRUCTION})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07b7a230-c230-4bbe-ab54-b9965a9b5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trlabs.rl.eval import setup_model_and_lora, generate\n",
    "\n",
    "index =10\n",
    "prompt = dataset[\"test\"][index][\"system\"]+dataset[\"test\"][index][\"messages\"]\n",
    "\n",
    "model, tokenizer = setup_model_and_lora(\n",
    "    base_model_name = model_config[\"model_name_or_path\"], \n",
    "    lora_path = training_params[\"output_dir\"]\n",
    ")\n",
    "\n",
    "response = generate(prompt, model, tokenizer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430b3a2-8f08-4b93-a5ee-0fa1f257db82",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "if you do not provide lora_path you can check the base model output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
